---
{"dg-publish":true,"permalink":"/1 数据分析/2 AB实验/0 AB实验 科学归因与增长利器/2 深入 AB 实验/4 AB 实验参与单元/","dgPassFrontmatter":true,"noteIcon":"","created":"2023-10-03T07:38:21.178+08:00","updated":"2023-10-06T13:55:11.088+08:00"}
---


> 实验参与单元的颗粒度可粗可细，选择什么样的实验参与单元取决于实验评估的需要        
# 4.1 实验参与单元的选择

## 4.1.1 常见的实验参与单元

1. 常见实验参与单元级别
	1. 元素级别
		1. 指对实验元素，如一篇文章、一首歌曲等进行随机分流并进行标识实验id的随机过程
		2. Interleaving 实验方法 基本过程
			1. 用户不进行随机分组，所有用户会受到算法A、算法B的推荐内容混合后的结果
			2. 用户可以同时看到算法A、B的推荐结果，却不知道内容由哪个算法推荐
			3. 通过计算不同算法推荐内容的用户观看时长等实验指标，来比较算法A和算法B
	2. 页面界别
		1. 产品页面被视为实验参与单元，进行实验的页面每打开一次，就会被随机函数分配到不同的实验组中
		2. 不同的用户打开相同的页面，相同的用户在不同的时间打开多次页面，都会分别算作一次实验参与，进而被分配实验id 和 实验组
		3. 常用于 web 端
	3. 会话级别
		1. 用户在网站的一次访问时查看的一组页面或是启动一次 APP后在 APP内的行为
	4. 用户级别
		1. 以用户为实验参与单元
2. 平衡用户体验与实验参与单元颗粒度，考虑2个关键因素
	1. 实验所需要的流量以及试验检测精度
	2. 用户体验的连续性
3. 一般流量足够的情况下，为了保证体验的稳定性和连续性，最好采用 用户级别
	1. 策略A、策略B，用户是否能明显感知到变化
		1. 能，说明用户体验连续性受到影响
4. 选择小粒度的实验参与单元，除了可以增加实验的流量外，还可以增加实验效果评估精度；在不影响体验连续性的前提下，从实验效果评估的角度，应该尽可能选择较小颗粒度的随机单元进行分流
5. 如果实验特征的粒度跨越实验参与单元的粒度起了作用，则不能用该粒度的实验参与单元进行分流

## 4.1.2 实验参与单元粒度与实验评估

1. 粗粒度的随机分流实验，可以往下兼容评估指标，细粒度的无法向上兼容
	1. 用户级别的随机分流实验，能往下细分评估会话、页面、元素级别的指标
2. 通常建议随机化单元与分析单元相同，或者随机化单元比分析单元粒度更粗
3. 如果指标是 OEC 的一部分，就不能使用更精细的粒度进行随机化（11章）

## 4.1.3 用户级别的实验参与单元

1. 选择用户级别的实验参与单元颗粒度仍是最主要的一种方式
	1. 具体体验稳定性
	2. 同时可以对用户进行长期观察
2. 常见用户标识
	1. 登录账户类，账号、手机号登
		1. 用户id稳定性最好，跨平台、跨设备可以识别同步
		2. 存在的问题：允许同时多设备使用，可能多人使用，用户行为会不同，对实验的分析结果会产生一定干扰
	2. 设备id类，绑定到某一个设备
		1. 不具有跨设备跨平台一致性
		2. 但一定时间内也具备一定的稳定性
		3. IOS 设备一般指 广告标识符
		4. 安卓设备一般指 国际移动设备识别码
3. 定向实验，针对一部分用户群体进行随机分流，会涉及如何处理用户中另一部分未被选择进行实验的问题。一般有2种方法
	1. 先锁定全部流量，然后从流量中筛选复合条件的进行实验打标，其余不符合条件的流量虽然不进行实验，但这部分流量也被实验占用
		1. 可以避免后面实验用户分布不均匀，缺点是流量浪费大
	2. 直接从流量中选取符合条件的用户进行实验，不符合条件的回归流量池
		1. 尽可能充分地使用流量
		2. 可能会造成同层级后续开启实验用户的分布和大盘用户分布不一致，从而无法很好评估实验全量后对大盘指标的提升效果
4. 示例：
	1. 100万用户，新用户20万，老用户80万，进行两种实验。新用户人均使用时长 10min，老用户 20min
	2. 方案一：
		1. 10万新用户，分为 A1 B1 两组进行实验1
		2. 10万新用户和80万老用户，分为 A2 B2 两组进行实验2
		3. 实验2 对新用户使用时长提升 2min，老用户 1min
		4. ![image.png](https://xunhuanke-1309879741.cos.ap-nanjing.myqcloud.com/blog/20231006121130.png)

		5. 实验2 提升效果（比较 A2 B2）
			1. 实验组 A2 的人均使用时长：`[80 * (20+1) + 10*(10+2)] / (80+10) = 20`
			2. 对照组 B2 的人均使用时长：`(80*20 + 10*10)/ (80+10) = 18.89`
			3. `(20-18.89)/18.89 约等于 5.87% `
		6. 但整体产品来说，新老用户构成是 `2:8`，所以需要修正实验2的影响
			1. 修正后 实验组 A2 的人均使用时长：`[80 * (20+1) + 20*(10+2)] / (80+20) = 19.2`
			2. 对照组 B2 的人均使用时长：18min
			3. 影响：`(19.2-18)/18 = 6.67% `
		7. 也就是实验2 对于大盘提升了 6.67%
	3. 方案二：
		1. 实验1需要 10万个新用户，按照新老用户比例抽取大盘中的 50万个用户，剩余 40万个被抽取的老用户不参与实验，且被锁定，不再参与其他实验的分流
		2. ![image.png](https://xunhuanke-1309879741.cos.ap-nanjing.myqcloud.com/blog/20231006121143.png)

		3. 效果：
			1. 实验组 A2 的人均使用时长：`[40 * (20+1) + 10*(10+2)] / (40+10) = 19.2`
			2. 对照组 B2 的人均使用时长：18min
			3. 影响：`(19.2-18)/18 = 6.67% `
	4. 流量够用的情况下，使用方案二，流量紧张选择方案一，并注意修正对大盘的影响。

# 4.2 实验参与单元与 SUTVA 问题

> 实验参与单元满足 SUTVA 是实验分析打的前提，如果实验单元不符合，得到的实验结论大概率是无效的

## 4.2.1 什么是 SUTVA

1. SUTVA
	1. Stable Unit Treatment Value Assumption
	2. 个体稳定性假设，是指在 AB实验分析中，假设实验中每个实验参与单元的行为是相互独立的，对于实验参与单元的情况来说，独立的意思是一个用户的行为不受其他用户的影响
	3. 如果 SUTVA 不成立，实验结果分析将导致结论不正确。
	4. 将违反 SUTVA 的情况称为干扰了个体处理稳定性假设，也称为实验参与单元之间的溢出或泄露

## 4.2.2 为什么需要让 SUTVA成立

1. AB实验因果分析主要基于 鲁宾因果模型（Rubin Causal Model, RCM），是AB实验分析打的一个标准框架，有3个基本要素
	1. 潜在结果
		1. 给定一个实验单元和一系列动作，把一个“实验单元 - 动作” 确定为一个潜在结果（理论上可能发生，但不一定实际发生）
		2. 对于任何一个实验单元，“处理动作”与“不处理动作”这2个潜在结果之间的差别就是处理的因果效用或者处理效果
		3. 处理效果定义为：`E = Y(处理动作) - Y(不处理动作)`
		4. 因果推断的基础问题是，对于同一个实验单元，最多只有一个潜在结果被实现，从而只有 一个潜在结果能被观测到，总有一个观测不到，即缺失值
		5. 当参与单元增加，观测不到的情况更多
	2. SUTVA
		1. 要解决相互影响导致的更多结果不可观测问题，可以假设实验参与单元之间互不影响，推而广之：任何单元的潜在结果不会因分配给其他单元的处理而变化，且对于每个单元，不同的处理对应唯一不同的结果，这就是 SUTVA
	3. 分配机制
		1. 要小心翼翼地保证实验组和对照组的人事先并不存在系统性偏差
		2. 即实验效果 = 实验组（实验） - 实验组（不实验）
		3. 实验效果 约等于  实验组（实验） - 实验组（不实验）+ 实验组（不实验） - 对照组（不实验）=  实验组（实验）- 对照组（不实验）
		4. 选择偏差 = 实验组（不实验） - 对照组（不实验）

## 4.2.3 导致 SUTVA 不成立的原因

1. 干扰个体处理稳定性的方式主要有两种：
	1. 直接连接
		1. 由于直接连接的单元的可以分成实验组和对照组，因此会在两个组之间造成干扰
			1. 对照组用户会受到实验组中用户的影响，对照组称为名义上的对照组
	2. 间接连接
		1. 通过某些潜在变量或共享资源，两个实验单元可以有间接连接
		2. 示例：
			1. 滴滴测试一种新的涨价算法，实验组的乘客更可能选择搭车，从而导致路上可以用的司机少了，间接导致对照组可用的司机少了，从而导致实验组、对照组的增量被高估了

## 4.2.4 如何解决 SUTVA 不成立的问题

### 1 建立监控和报警

1. 检测极端干扰问题
### 2 隔离法

1. 干预连接实验组和对照组的介质发生作用，通过识别连接介质并隔离用户消除潜在用户
2. 隔离方法：
	1. 共享资源隔离
		1. 干扰资源是否可以完全按照用户的流量分配进行划分
		2. 流量分配是否存在偏差，对于训练数据，模型的性能随着训练数据的增加而提高
		3. 示例，在线广告实验，实验组、对照组共享了广告预算
			1. 防止预算窃取的一种方式是，按照暴漏于实验组和对照组的用户流量百分比来分割所有广告预算
			2. 合理选择实验指标，也是至关重要的，可以对比 预算使用率
	2. 地理位置隔离
		1. 可以通过地理位置的大小来限制样本大小
		2. 但也会导致 AB 实验的方差较大，降低功效
	3. 网络族群隔离
		1. 在社交网络上，根据节点干扰的可能性构建彼此接近的节点的簇，然后将簇作为“巨型”单元独立、随机分为实验组和对照组
		2. 局限性
			1. 实践中很少有完全孤立的情况
			2. 大单元随机方法，带来的有效样本量（聚类数）通常较小，导致在构建聚类时需要权衡方差和偏差

### 3 边缘度分析

1. 一些泄露发生在两个用户之间明确定义的交互中，这些相互作用很容易识别
	1. 在数学上可以看做一条有方向的边
		1. 从实验组到实验组的边
		2. 从实验组到对照组的边
		3. 从对照组到实验组的边
		4. 从对照组到对照组的边
	2. 对比不同边的交互，可以了解网络互动效果的影响程度

### 4 生态经验法

1. 只关心会溢出的操作，只有这些操作在实验中受到实质性影响时，才会担心干扰
2. 不仅关心一阶动作，还要关心一阶动作的潜在反应
	1. 需要对一阶动作的影响，进行测量（确定某些指标）
	2. 建立关于每个行动如何转化为整个系统的价值或参与的普适指导
	3. 建立这一经验法则，可以使用被证明具有下游影响的历史经验，并外推到其他行动的下游影响
3. 经验法则相对容易实现但只是近似值，不适用于所有场景

### 5 双边随机化

1. 同时有内容生产者和消费者的场景下，如何进行AB测试
2. 两个正交实验（生产实验组-消费实验组，生产实验组-消费对照组，生成对照组-消费实验组，生成对照组-消费对照组）
	1. 一个控制生产体验
		1. 实验组 用户将标签添加到帖子中
	2. 一个控制消费体验
		1. 实验组 用户在他们的提要上看到标签
	3. 由于实际参与实验的 生产组、对照组比列 与 实验参与单元的比例不一致，可能导致 实验效果被低估或高估

# 4.3 最小实验参与单元数量


1. 实际操作，样本量少的好处
	1. 流量有限
	2. 试错成本高
2. 关键问题
	1. 如何确定一个最小样本数量
	2. 考虑以下四个因素
		1. 显著性水平
		2. 统计功效
		3. 基线水平
		4. 最小检出水平

### 1 显著性水平

1. 一般用 α 表示，是第一类错误出现的概率，用于控制第一类错误
	1. 第一类错误（实验中表现为实验没有效果，却被判断为有效果）
	2. 实践中，公司一般会选择一个可以接受的 α 作为上限，常见的为 5%
### 2 统计功效

1. 一般用 `1- β` 表示，指实验本身有效同事也被判断为有效的概率
	1. β 表示第二类错误发生概率，即实验本身有效果，却被判断为无效
2. 一般来说，统计功效要在 80% 以上
3. 对于一个 AB实验来说
	1. 第一类错误不超过 5%，即 α <= 5%
	2. 第二类错误不超过 20%，即 `1- β` >= 80%
	3. 背后的理念为，宁可4个好的产品不上线，也不要上线1个好的产品

### 3 基线水平

1. 指在实验开始之前，对照组中所关心的实验指标的表现情况，也就是不做改变时的指标水平
2. 比率类指标
	1. 对于比率类的指标，从直观上来理解，当基线水平很大，或者很小时，很容易检测出差别
	2. 所以假设基线水平为 0.5 时，计算出来的样本数量，是最大值
3. 均值类指标
	1. 主要考虑对照组的方差分布，如果方差小，意味着波动小，那么实验更容易检测出差别，所需样本数少
	2. 如果方差大，那么波动大，实验不容易检测出差别，功效变小，要维持功效不变，所需要的样本数量变大
4. ![image.png](https://xunhuanke-1309879741.cos.ap-nanjing.myqcloud.com/blog/20231006132616.png)


### 4 最小检出水平

1. 用于衡量实验判断精确度的最低要求
	1. 参数越大，说明精确度越低
2. 工作中，最小检出水平参数的选定往往需要和业务方一起商定
3. *为了将第一类错误和第二类错误控制在一定范围内，达到一定的实验置信度和业务评估精度，需要实验单元的参与数量满足最小样本量*
4. 小工具：https://www.evanmiller.org/ab-testing/sample-size.html